{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very slightly modified fork of Microsoft's [Fast Retraining](https://github.com/Azure/fast_retraining/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: HIGGS boson \n",
    "\n",
    "This experiment uses the data from the [HIGGS dataset](https://archive.ics.uci.edu/ml/datasets/HIGGS) to predict the appearance of the Higgs boson. The dataset consists of 11 million of observations.\n",
    "\n",
    "Dataset of atomic particles measurements. The total size of the data is 11 millions of observations. \n",
    "It can be used in a classification problem to distinguish between a signal process which produces Higgs \n",
    "bosons and a background process which does not.\n",
    "The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic \n",
    "properties measured by the particle detectors in the accelerator. The last seven features are functions of \n",
    "the first 21 features; these are high-level features derived by physicists to help discriminate between the \n",
    "two classes. The first column is the class label (1 for signal, 0 for background), followed by the 28 \n",
    "features (21 low-level features then 7 high-level features): lepton pT, lepton eta, lepton phi, \n",
    "missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, \n",
    "jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, \n",
    "jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb.\n",
    "\n",
    "Link to the source: https://archive.ics.uci.edu/ml/datasets/HIGGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing is done on my home computer\n",
    "\n",
    "    CPU: Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz\n",
    "    RAM: 32GiB (4 x 8GiB DIMM Synchronous 2133 MHz (0.5 ns)\n",
    "    OS: Ubuntu 16.04.4 LTS\n",
    "    Storage: Samsung SSD 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.5.2 (default, Nov 23 2017, 16:37:01) \n",
      "[GCC 5.4.0 20160609]\n",
      "XGBoost version: 0.71\n",
      "LightGBM version: 2.1.1\n",
      "CatBoost version: 0.8.1.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pkg_resources\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from timer import Timer\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"XGBoost version: {}\".format(pkg_resources.get_distribution('xgboost').version))\n",
    "print(\"LightGBM version: {}\".format(pkg_resources.get_distribution('lightgbm').version))\n",
    "print(\"CatBoost version: {}\".format(pkg_resources.get_distribution('catboost').version))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [2] used 0.2461 MiB RAM in 0.10s, total RAM usage 120.56 MiB\n"
     ]
    }
   ],
   "source": [
    "import notebook_memory_management\n",
    "notebook_memory_management.start_watching_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [3] used 0.0000 MiB RAM in 0.10s, total RAM usage 120.56 MiB\n"
     ]
    }
   ],
   "source": [
    "HIGGS_PATH = \"data/HIGGS.csv.gz\"\n",
    "\n",
    "def load_higgs():\n",
    "    \"\"\" Loads HIGGS data\n",
    "    \n",
    "    Dataset of atomic particles measurements. The total size of the data is 11 millions of observations. \n",
    "    It can be used in a classification problem to distinguish between a signal process which produces Higgs \n",
    "    bosons and a background process which does not.\n",
    "    The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic \n",
    "    properties measured by the particle detectors in the accelerator. The last seven features are functions of \n",
    "    the first 21 features; these are high-level features derived by physicists to help discriminate between the \n",
    "    two classes. The first column is the class label (1 for signal, 0 for background), followed by the 28 \n",
    "    features (21 low-level features then 7 high-level features): lepton pT, lepton eta, lepton phi, \n",
    "    missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, \n",
    "    jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, \n",
    "    jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb.\n",
    "    Link to the source: https://archive.ics.uci.edu/ml/datasets/HIGGS\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    cols = ['boson','lepton_pT','lepton_eta','lepton_phi','missing_energy_magnitude','missing_energy_phi','jet_1_pt','jet_1_eta','jet_1_phi','jet_1_b-tag','jet_2_pt','jet_2_eta','jet_2_phi','jet_2_b-tag','jet_3_pt','jet_3_eta','jet_3_phi','jet_3_b-tag','jet_4_pt','jet_4_eta','jet_4_phi','jet_4_b-tag','m_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb']\n",
    "    return pd.read_csv(HIGGS_PATH, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000000, 29)\n",
      "CPU times: user 1min 39s, sys: 2.43 s, total: 1min 41s\n",
      "Wall time: 1min 41s\n",
      "In [4] used 4807.1523 MiB RAM in 101.85s, total RAM usage 4927.71 MiB\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = load_higgs()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boson</th>\n",
       "      <th>lepton_pT</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet_1_pt</th>\n",
       "      <th>jet_1_eta</th>\n",
       "      <th>jet_1_phi</th>\n",
       "      <th>jet_1_b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet_4_eta</th>\n",
       "      <th>jet_4_phi</th>\n",
       "      <th>jet_4_b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   boson  lepton_pT  lepton_eta  lepton_phi  missing_energy_magnitude  \\\n",
       "0    1.0   0.869293   -0.635082    0.225690                  0.327470   \n",
       "1    1.0   0.907542    0.329147    0.359412                  1.497970   \n",
       "2    1.0   0.798835    1.470639   -1.635975                  0.453773   \n",
       "3    0.0   1.344385   -0.876626    0.935913                  1.992050   \n",
       "4    1.0   1.105009    0.321356    1.522401                  0.882808   \n",
       "\n",
       "   missing_energy_phi  jet_1_pt  jet_1_eta  jet_1_phi  jet_1_b-tag    ...     \\\n",
       "0           -0.689993  0.754202  -0.248573  -1.092064     0.000000    ...      \n",
       "1           -0.313010  1.095531  -0.557525  -1.588230     2.173076    ...      \n",
       "2            0.425629  1.104875   1.282322   1.381664     0.000000    ...      \n",
       "3            0.882454  1.786066  -1.646778  -0.942383     0.000000    ...      \n",
       "4           -1.205349  0.681466  -1.070464  -0.921871     0.000000    ...      \n",
       "\n",
       "   jet_4_eta  jet_4_phi  jet_4_b-tag      m_jj     m_jjj      m_lv     m_jlv  \\\n",
       "0  -0.010455  -0.045767     3.101961  1.353760  0.979563  0.978076  0.920005   \n",
       "1  -1.138930  -0.000819     0.000000  0.302220  0.833048  0.985700  0.978098   \n",
       "2   1.128848   0.900461     0.000000  0.909753  1.108330  0.985692  0.951331   \n",
       "3  -0.678379  -1.360356     0.000000  0.946652  1.028704  0.998656  0.728281   \n",
       "4  -0.373566   0.113041     0.000000  0.755856  1.361057  0.986610  0.838085   \n",
       "\n",
       "       m_bb     m_wbb    m_wwbb  \n",
       "0  0.721657  0.988751  0.876678  \n",
       "1  0.779732  0.992356  0.798343  \n",
       "2  0.803252  0.865924  0.780118  \n",
       "3  0.869200  1.026736  0.957904  \n",
       "4  1.133295  0.872245  0.808487  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [5] used 0.0000 MiB RAM in 0.14s, total RAM usage 4927.71 MiB\n"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cols = ['boson','lepton_pT','lepton_eta','lepton_phi','missing_energy_magnitude','missing_energy_phi','jet_1_pt','jet_1_eta','jet_1_phi','jet_1_b-tag','jet_2_pt','jet_2_eta','jet_2_phi','jet_2_b-tag','jet_3_pt','jet_3_eta','jet_3_phi','jet_3_b-tag','jet_4_pt','jet_4_eta','jet_4_phi','jet_4_b-tag','m_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb']\n",
    "df = pd.read_csv(\"data/HIGGS-sample.csv\", names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5274975002272521"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.boson.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_processors = 8\n",
      "In [6] used 0.0000 MiB RAM in 0.10s, total RAM usage 4927.71 MiB\n"
     ]
    }
   ],
   "source": [
    "num_rounds = 200\n",
    "number_processors = os.cpu_count()\n",
    "print(\"number_processors =\", number_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [7] used 0.0000 MiB RAM in 0.11s, total RAM usage 4927.71 MiB\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'AUC': roc_auc_score,\n",
    "    'F1': f1_score,\n",
    "}\n",
    "\n",
    "def classification_metrics(metrics, y_true, y_pred):\n",
    "    return {metric_name:metric(y_true, y_pred) for metric_name, metric in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [8] used 0.0000 MiB RAM in 0.10s, total RAM usage 4927.71 MiB\n"
     ]
    }
   ],
   "source": [
    "def generate_feables(df):\n",
    "    X = df[df.columns.difference(['boson'])]\n",
    "    y = df['boson']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [9] used 2350.2422 MiB RAM in 0.84s, total RAM usage 7277.95 MiB\n"
     ]
    }
   ],
   "source": [
    "X, y = generate_feables(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [10] used 2243.7266 MiB RAM in 6.78s, total RAM usage 9521.68 MiB\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=77, test_size=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [11] used 0.0000 MiB RAM in 0.11s, total RAM usage 9521.68 MiB\n"
     ]
    }
   ],
   "source": [
    "results_dict = dict()\n",
    "\n",
    "def extend_result(name, train_t, test_t, y_pred):\n",
    "    results_dict[name] = {\n",
    "        'train_time': t_train.interval,\n",
    "        'train_mem': t_train.memory,\n",
    "        'test_time': t_test.interval,\n",
    "        'train_mem': t_test.memory,\n",
    "        'performance': classification_metrics(metrics_dict, y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [12] used 0.0000 MiB RAM in 0.11s, total RAM usage 9521.68 MiB\n"
     ]
    }
   ],
   "source": [
    "xgb_hist_clf_pipeline = XGBClassifier(max_depth=0,\n",
    "                                      learning_rate=0.1,\n",
    "                                      scale_pos_weight=2,\n",
    "                                      n_estimators=num_rounds,\n",
    "                                      gamma=0.1,\n",
    "                                      min_child_weight=1,\n",
    "                                      reg_lambda=1,\n",
    "                                      subsample=1,\n",
    "                                      max_leaves=2**5,\n",
    "                                      grow_policy='lossguide',\n",
    "                                      tree_method='hist',\n",
    "                                      nthread=number_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [13] used 4682.0898 MiB RAM in 199.80s, total RAM usage 14203.77 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t_train:\n",
    "    xgb_hist_clf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "with Timer() as t_test:\n",
    "    y_pred = xgb_hist_clf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [14] used 0.0000 MiB RAM in 0.55s, total RAM usage 14203.77 MiB\n"
     ]
    }
   ],
   "source": [
    "extend_result('xgb_hist', t_train, t_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [15] used 0.0000 MiB RAM in 0.10s, total RAM usage 14203.77 MiB\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf_pipeline = LGBMClassifier(num_leaves=2**5, \n",
    "                                   learning_rate=0.1, \n",
    "                                   scale_pos_weight=2,\n",
    "                                   n_estimators=num_rounds,\n",
    "                                   min_split_gain=0.1,\n",
    "                                   min_child_weight=1,\n",
    "                                   reg_lambda=1,\n",
    "                                   subsample=1,\n",
    "                                   nthread=number_processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [16] used 2243.6211 MiB RAM in 123.14s, total RAM usage 16447.39 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t_train:\n",
    "    lgbm_clf_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "with Timer() as t_test:\n",
    "    y_pred = lgbm_clf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [17] used 0.0000 MiB RAM in 0.63s, total RAM usage 16447.39 MiB\n"
     ]
    }
   ],
   "source": [
    "extend_result('lgbm', t_train, t_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [18] used 0.0000 MiB RAM in 0.10s, total RAM usage 16447.39 MiB\n"
     ]
    }
   ],
   "source": [
    "catboost_clf1 = CatBoostClassifier(iterations=50,  depth=10, learning_rate=0.75, use_best_model=True)\n",
    "catboost_clf2 = CatBoostClassifier(iterations=100, depth=10, learning_rate=0.75, use_best_model=True)\n",
    "catboost_clf3 = CatBoostClassifier(iterations=200, depth=10, learning_rate=0.75, use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5984543\ttest: 0.5978012\tbest: 0.5978012 (0)\ttotal: 3.21s\tremaining: 2m 37s\n",
      "1:\tlearn: 0.5769844\ttest: 0.5759589\tbest: 0.5759589 (1)\ttotal: 6.31s\tremaining: 2m 31s\n",
      "2:\tlearn: 0.5657624\ttest: 0.5648693\tbest: 0.5648693 (2)\ttotal: 9.42s\tremaining: 2m 27s\n",
      "3:\tlearn: 0.5581784\ttest: 0.5570759\tbest: 0.5570759 (3)\ttotal: 12.6s\tremaining: 2m 24s\n",
      "4:\tlearn: 0.5526425\ttest: 0.5516414\tbest: 0.5516414 (4)\ttotal: 15.7s\tremaining: 2m 21s\n",
      "5:\tlearn: 0.5483744\ttest: 0.5474873\tbest: 0.5474873 (5)\ttotal: 18.7s\tremaining: 2m 17s\n",
      "6:\tlearn: 0.5454438\ttest: 0.5444752\tbest: 0.5444752 (6)\ttotal: 21.9s\tremaining: 2m 14s\n",
      "7:\tlearn: 0.5433435\ttest: 0.5424801\tbest: 0.5424801 (7)\ttotal: 25s\tremaining: 2m 11s\n",
      "8:\tlearn: 0.5414438\ttest: 0.5406867\tbest: 0.5406867 (8)\ttotal: 28s\tremaining: 2m 7s\n",
      "9:\tlearn: 0.5390634\ttest: 0.5382806\tbest: 0.5382806 (9)\ttotal: 31.2s\tremaining: 2m 4s\n",
      "10:\tlearn: 0.5371265\ttest: 0.5363774\tbest: 0.5363774 (10)\ttotal: 34.2s\tremaining: 2m 1s\n",
      "11:\tlearn: 0.5350353\ttest: 0.5344325\tbest: 0.5344325 (11)\ttotal: 37.4s\tremaining: 1m 58s\n",
      "12:\tlearn: 0.5332233\ttest: 0.5326106\tbest: 0.5326106 (12)\ttotal: 40.5s\tremaining: 1m 55s\n",
      "13:\tlearn: 0.5319674\ttest: 0.5314494\tbest: 0.5314494 (13)\ttotal: 43.6s\tremaining: 1m 52s\n",
      "14:\tlearn: 0.5308875\ttest: 0.5303610\tbest: 0.5303610 (14)\ttotal: 46.7s\tremaining: 1m 48s\n",
      "15:\tlearn: 0.5296807\ttest: 0.5291288\tbest: 0.5291288 (15)\ttotal: 49.8s\tremaining: 1m 45s\n",
      "16:\tlearn: 0.5288226\ttest: 0.5283903\tbest: 0.5283903 (16)\ttotal: 52.8s\tremaining: 1m 42s\n",
      "17:\tlearn: 0.5272856\ttest: 0.5268294\tbest: 0.5268294 (17)\ttotal: 55.9s\tremaining: 1m 39s\n",
      "18:\tlearn: 0.5263406\ttest: 0.5258981\tbest: 0.5258981 (18)\ttotal: 58.9s\tremaining: 1m 36s\n",
      "19:\tlearn: 0.5254695\ttest: 0.5250993\tbest: 0.5250993 (19)\ttotal: 1m 2s\tremaining: 1m 33s\n",
      "20:\tlearn: 0.5245686\ttest: 0.5242632\tbest: 0.5242632 (20)\ttotal: 1m 5s\tremaining: 1m 29s\n",
      "21:\tlearn: 0.5237902\ttest: 0.5235671\tbest: 0.5235671 (21)\ttotal: 1m 8s\tremaining: 1m 26s\n",
      "22:\tlearn: 0.5230020\ttest: 0.5227584\tbest: 0.5227584 (22)\ttotal: 1m 11s\tremaining: 1m 23s\n",
      "23:\tlearn: 0.5221592\ttest: 0.5219643\tbest: 0.5219643 (23)\ttotal: 1m 14s\tremaining: 1m 20s\n",
      "24:\tlearn: 0.5213621\ttest: 0.5211911\tbest: 0.5211911 (24)\ttotal: 1m 17s\tremaining: 1m 17s\n",
      "25:\tlearn: 0.5207782\ttest: 0.5206382\tbest: 0.5206382 (25)\ttotal: 1m 20s\tremaining: 1m 14s\n",
      "26:\tlearn: 0.5200202\ttest: 0.5199374\tbest: 0.5199374 (26)\ttotal: 1m 23s\tremaining: 1m 11s\n",
      "27:\tlearn: 0.5195609\ttest: 0.5194984\tbest: 0.5194984 (27)\ttotal: 1m 26s\tremaining: 1m 8s\n",
      "28:\tlearn: 0.5188943\ttest: 0.5189083\tbest: 0.5189083 (28)\ttotal: 1m 29s\tremaining: 1m 5s\n",
      "29:\tlearn: 0.5182238\ttest: 0.5183053\tbest: 0.5183053 (29)\ttotal: 1m 32s\tremaining: 1m 1s\n",
      "30:\tlearn: 0.5175650\ttest: 0.5176742\tbest: 0.5176742 (30)\ttotal: 1m 36s\tremaining: 58.9s\n",
      "31:\tlearn: 0.5169699\ttest: 0.5171685\tbest: 0.5171685 (31)\ttotal: 1m 39s\tremaining: 55.8s\n",
      "32:\tlearn: 0.5164524\ttest: 0.5166729\tbest: 0.5166729 (32)\ttotal: 1m 42s\tremaining: 52.7s\n",
      "33:\tlearn: 0.5160361\ttest: 0.5163160\tbest: 0.5163160 (33)\ttotal: 1m 45s\tremaining: 49.6s\n",
      "34:\tlearn: 0.5153849\ttest: 0.5156756\tbest: 0.5156756 (34)\ttotal: 1m 48s\tremaining: 46.5s\n",
      "35:\tlearn: 0.5148566\ttest: 0.5152233\tbest: 0.5152233 (35)\ttotal: 1m 51s\tremaining: 43.4s\n",
      "36:\tlearn: 0.5142903\ttest: 0.5146470\tbest: 0.5146470 (36)\ttotal: 1m 54s\tremaining: 40.3s\n",
      "37:\tlearn: 0.5134009\ttest: 0.5138273\tbest: 0.5138273 (37)\ttotal: 1m 57s\tremaining: 37.2s\n",
      "38:\tlearn: 0.5131153\ttest: 0.5136106\tbest: 0.5136106 (38)\ttotal: 2m\tremaining: 34.1s\n",
      "39:\tlearn: 0.5124317\ttest: 0.5129571\tbest: 0.5129571 (39)\ttotal: 2m 4s\tremaining: 31s\n",
      "40:\tlearn: 0.5120337\ttest: 0.5126353\tbest: 0.5126353 (40)\ttotal: 2m 7s\tremaining: 27.9s\n",
      "41:\tlearn: 0.5116888\ttest: 0.5123417\tbest: 0.5123417 (41)\ttotal: 2m 10s\tremaining: 24.8s\n",
      "42:\tlearn: 0.5109601\ttest: 0.5116575\tbest: 0.5116575 (42)\ttotal: 2m 13s\tremaining: 21.7s\n",
      "43:\tlearn: 0.5104742\ttest: 0.5112612\tbest: 0.5112612 (43)\ttotal: 2m 16s\tremaining: 18.6s\n",
      "44:\tlearn: 0.5101313\ttest: 0.5109222\tbest: 0.5109222 (44)\ttotal: 2m 19s\tremaining: 15.5s\n",
      "45:\tlearn: 0.5098222\ttest: 0.5106359\tbest: 0.5106359 (45)\ttotal: 2m 22s\tremaining: 12.4s\n",
      "46:\tlearn: 0.5094140\ttest: 0.5103023\tbest: 0.5103023 (46)\ttotal: 2m 26s\tremaining: 9.32s\n",
      "47:\tlearn: 0.5089479\ttest: 0.5098888\tbest: 0.5098888 (47)\ttotal: 2m 29s\tremaining: 6.22s\n",
      "48:\tlearn: 0.5085998\ttest: 0.5095475\tbest: 0.5095475 (48)\ttotal: 2m 32s\tremaining: 3.11s\n",
      "49:\tlearn: 0.5082097\ttest: 0.5092005\tbest: 0.5092005 (49)\ttotal: 2m 35s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.509200533\n",
      "bestIteration = 49\n",
      "\n",
      "Shrink model to first 50 iterations.\n",
      "In [19] used 4299.5391 MiB RAM in 222.30s, total RAM usage 20746.93 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t_train: \n",
    "    catboost_clf1.fit(X_train, y_train, cat_features=[], eval_set=(X_test, y_test), verbose=True, plot=False)\n",
    "with Timer() as t_test:  \n",
    "    y_pred = catboost_clf1.predict(X_test)\n",
    "extend_result('catboost1', t_train, t_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5985638\ttest: 0.5978893\tbest: 0.5978893 (0)\ttotal: 3.16s\tremaining: 5m 13s\n",
      "1:\tlearn: 0.5788223\ttest: 0.5778533\tbest: 0.5778533 (1)\ttotal: 6.28s\tremaining: 5m 7s\n",
      "2:\tlearn: 0.5652920\ttest: 0.5643083\tbest: 0.5643083 (2)\ttotal: 9.39s\tremaining: 5m 3s\n",
      "3:\tlearn: 0.5578412\ttest: 0.5571759\tbest: 0.5571759 (3)\ttotal: 12.5s\tremaining: 5m\n",
      "4:\tlearn: 0.5525221\ttest: 0.5519408\tbest: 0.5519408 (4)\ttotal: 15.6s\tremaining: 4m 56s\n",
      "5:\tlearn: 0.5493542\ttest: 0.5487470\tbest: 0.5487470 (5)\ttotal: 18.8s\tremaining: 4m 54s\n",
      "6:\tlearn: 0.5452024\ttest: 0.5446291\tbest: 0.5446291 (6)\ttotal: 22s\tremaining: 4m 52s\n",
      "7:\tlearn: 0.5432375\ttest: 0.5427703\tbest: 0.5427703 (7)\ttotal: 25.1s\tremaining: 4m 48s\n",
      "8:\tlearn: 0.5400723\ttest: 0.5396200\tbest: 0.5396200 (8)\ttotal: 28.2s\tremaining: 4m 44s\n",
      "9:\tlearn: 0.5384773\ttest: 0.5379934\tbest: 0.5379934 (9)\ttotal: 31.2s\tremaining: 4m 40s\n",
      "10:\tlearn: 0.5360142\ttest: 0.5356756\tbest: 0.5356756 (10)\ttotal: 34.4s\tremaining: 4m 38s\n",
      "11:\tlearn: 0.5345165\ttest: 0.5341581\tbest: 0.5341581 (11)\ttotal: 37.5s\tremaining: 4m 34s\n",
      "12:\tlearn: 0.5329659\ttest: 0.5327164\tbest: 0.5327164 (12)\ttotal: 40.6s\tremaining: 4m 31s\n",
      "13:\tlearn: 0.5313658\ttest: 0.5312446\tbest: 0.5312446 (13)\ttotal: 43.7s\tremaining: 4m 28s\n",
      "14:\tlearn: 0.5297804\ttest: 0.5297453\tbest: 0.5297453 (14)\ttotal: 46.9s\tremaining: 4m 25s\n",
      "15:\tlearn: 0.5287351\ttest: 0.5288154\tbest: 0.5288154 (15)\ttotal: 50s\tremaining: 4m 22s\n",
      "16:\tlearn: 0.5274887\ttest: 0.5276210\tbest: 0.5276210 (16)\ttotal: 53.1s\tremaining: 4m 19s\n",
      "17:\tlearn: 0.5265665\ttest: 0.5267017\tbest: 0.5267017 (17)\ttotal: 56.2s\tremaining: 4m 16s\n",
      "18:\tlearn: 0.5256441\ttest: 0.5258292\tbest: 0.5258292 (18)\ttotal: 59.3s\tremaining: 4m 12s\n",
      "19:\tlearn: 0.5245539\ttest: 0.5247846\tbest: 0.5247846 (19)\ttotal: 1m 2s\tremaining: 4m 9s\n",
      "20:\tlearn: 0.5235422\ttest: 0.5238667\tbest: 0.5238667 (20)\ttotal: 1m 5s\tremaining: 4m 6s\n",
      "21:\tlearn: 0.5221979\ttest: 0.5226196\tbest: 0.5226196 (21)\ttotal: 1m 8s\tremaining: 4m 3s\n",
      "22:\tlearn: 0.5212956\ttest: 0.5218084\tbest: 0.5218084 (22)\ttotal: 1m 11s\tremaining: 4m\n",
      "23:\tlearn: 0.5206412\ttest: 0.5211403\tbest: 0.5211403 (23)\ttotal: 1m 14s\tremaining: 3m 56s\n",
      "24:\tlearn: 0.5199124\ttest: 0.5204413\tbest: 0.5204413 (24)\ttotal: 1m 17s\tremaining: 3m 53s\n",
      "25:\tlearn: 0.5192990\ttest: 0.5198445\tbest: 0.5198445 (25)\ttotal: 1m 20s\tremaining: 3m 50s\n",
      "26:\tlearn: 0.5185468\ttest: 0.5190980\tbest: 0.5190980 (26)\ttotal: 1m 24s\tremaining: 3m 47s\n",
      "27:\tlearn: 0.5178730\ttest: 0.5185003\tbest: 0.5185003 (27)\ttotal: 1m 27s\tremaining: 3m 44s\n",
      "28:\tlearn: 0.5172089\ttest: 0.5179017\tbest: 0.5179017 (28)\ttotal: 1m 30s\tremaining: 3m 41s\n",
      "29:\tlearn: 0.5167183\ttest: 0.5173940\tbest: 0.5173940 (29)\ttotal: 1m 33s\tremaining: 3m 38s\n",
      "30:\tlearn: 0.5161186\ttest: 0.5168551\tbest: 0.5168551 (30)\ttotal: 1m 36s\tremaining: 3m 35s\n",
      "31:\tlearn: 0.5157010\ttest: 0.5164593\tbest: 0.5164593 (31)\ttotal: 1m 39s\tremaining: 3m 31s\n",
      "32:\tlearn: 0.5152290\ttest: 0.5159857\tbest: 0.5159857 (32)\ttotal: 1m 42s\tremaining: 3m 28s\n",
      "33:\tlearn: 0.5147728\ttest: 0.5155382\tbest: 0.5155382 (33)\ttotal: 1m 45s\tremaining: 3m 25s\n",
      "34:\tlearn: 0.5139743\ttest: 0.5147945\tbest: 0.5147945 (34)\ttotal: 1m 48s\tremaining: 3m 22s\n",
      "35:\tlearn: 0.5135913\ttest: 0.5144522\tbest: 0.5144522 (35)\ttotal: 1m 51s\tremaining: 3m 19s\n",
      "36:\tlearn: 0.5131770\ttest: 0.5140096\tbest: 0.5140096 (36)\ttotal: 1m 55s\tremaining: 3m 15s\n",
      "37:\tlearn: 0.5127391\ttest: 0.5135602\tbest: 0.5135602 (37)\ttotal: 1m 58s\tremaining: 3m 12s\n",
      "38:\tlearn: 0.5123835\ttest: 0.5132711\tbest: 0.5132711 (38)\ttotal: 2m 1s\tremaining: 3m 9s\n",
      "39:\tlearn: 0.5117687\ttest: 0.5127713\tbest: 0.5127713 (39)\ttotal: 2m 4s\tremaining: 3m 6s\n",
      "40:\tlearn: 0.5114310\ttest: 0.5124969\tbest: 0.5124969 (40)\ttotal: 2m 7s\tremaining: 3m 3s\n",
      "41:\tlearn: 0.5110124\ttest: 0.5121242\tbest: 0.5121242 (41)\ttotal: 2m 10s\tremaining: 3m\n",
      "42:\tlearn: 0.5107641\ttest: 0.5118859\tbest: 0.5118859 (42)\ttotal: 2m 13s\tremaining: 2m 57s\n",
      "43:\tlearn: 0.5103275\ttest: 0.5115423\tbest: 0.5115423 (43)\ttotal: 2m 16s\tremaining: 2m 54s\n",
      "44:\tlearn: 0.5101269\ttest: 0.5113699\tbest: 0.5113699 (44)\ttotal: 2m 19s\tremaining: 2m 50s\n",
      "45:\tlearn: 0.5097637\ttest: 0.5110665\tbest: 0.5110665 (45)\ttotal: 2m 23s\tremaining: 2m 47s\n",
      "46:\tlearn: 0.5094957\ttest: 0.5108115\tbest: 0.5108115 (46)\ttotal: 2m 26s\tremaining: 2m 44s\n",
      "47:\tlearn: 0.5090803\ttest: 0.5104108\tbest: 0.5104108 (47)\ttotal: 2m 29s\tremaining: 2m 41s\n",
      "48:\tlearn: 0.5087027\ttest: 0.5100682\tbest: 0.5100682 (48)\ttotal: 2m 32s\tremaining: 2m 38s\n",
      "49:\tlearn: 0.5083145\ttest: 0.5097124\tbest: 0.5097124 (49)\ttotal: 2m 35s\tremaining: 2m 35s\n",
      "50:\tlearn: 0.5077632\ttest: 0.5092657\tbest: 0.5092657 (50)\ttotal: 2m 38s\tremaining: 2m 32s\n",
      "51:\tlearn: 0.5073867\ttest: 0.5089478\tbest: 0.5089478 (51)\ttotal: 2m 41s\tremaining: 2m 29s\n",
      "52:\tlearn: 0.5070974\ttest: 0.5087068\tbest: 0.5087068 (52)\ttotal: 2m 44s\tremaining: 2m 26s\n",
      "53:\tlearn: 0.5065798\ttest: 0.5082822\tbest: 0.5082822 (53)\ttotal: 2m 48s\tremaining: 2m 23s\n",
      "54:\tlearn: 0.5063271\ttest: 0.5080386\tbest: 0.5080386 (54)\ttotal: 2m 51s\tremaining: 2m 20s\n",
      "55:\tlearn: 0.5059689\ttest: 0.5077325\tbest: 0.5077325 (55)\ttotal: 2m 54s\tremaining: 2m 17s\n",
      "56:\tlearn: 0.5057454\ttest: 0.5075165\tbest: 0.5075165 (56)\ttotal: 2m 57s\tremaining: 2m 13s\n",
      "57:\tlearn: 0.5053921\ttest: 0.5072031\tbest: 0.5072031 (57)\ttotal: 3m\tremaining: 2m 10s\n",
      "58:\tlearn: 0.5049476\ttest: 0.5068088\tbest: 0.5068088 (58)\ttotal: 3m 3s\tremaining: 2m 7s\n",
      "59:\tlearn: 0.5047441\ttest: 0.5066604\tbest: 0.5066604 (59)\ttotal: 3m 6s\tremaining: 2m 4s\n",
      "60:\tlearn: 0.5043907\ttest: 0.5063641\tbest: 0.5063641 (60)\ttotal: 3m 10s\tremaining: 2m 1s\n",
      "61:\tlearn: 0.5041504\ttest: 0.5061820\tbest: 0.5061820 (61)\ttotal: 3m 13s\tremaining: 1m 58s\n",
      "62:\tlearn: 0.5038899\ttest: 0.5059711\tbest: 0.5059711 (62)\ttotal: 3m 16s\tremaining: 1m 55s\n",
      "63:\tlearn: 0.5035902\ttest: 0.5057670\tbest: 0.5057670 (63)\ttotal: 3m 19s\tremaining: 1m 52s\n",
      "64:\tlearn: 0.5033725\ttest: 0.5055981\tbest: 0.5055981 (64)\ttotal: 3m 22s\tremaining: 1m 48s\n",
      "65:\tlearn: 0.5031121\ttest: 0.5054418\tbest: 0.5054418 (65)\ttotal: 3m 25s\tremaining: 1m 45s\n",
      "66:\tlearn: 0.5028161\ttest: 0.5052517\tbest: 0.5052517 (66)\ttotal: 3m 28s\tremaining: 1m 42s\n",
      "67:\tlearn: 0.5024527\ttest: 0.5049420\tbest: 0.5049420 (67)\ttotal: 3m 31s\tremaining: 1m 39s\n",
      "68:\tlearn: 0.5022073\ttest: 0.5047848\tbest: 0.5047848 (68)\ttotal: 3m 35s\tremaining: 1m 36s\n",
      "69:\tlearn: 0.5019955\ttest: 0.5046507\tbest: 0.5046507 (69)\ttotal: 3m 38s\tremaining: 1m 33s\n",
      "70:\tlearn: 0.5017133\ttest: 0.5043820\tbest: 0.5043820 (70)\ttotal: 3m 41s\tremaining: 1m 30s\n",
      "71:\tlearn: 0.5014693\ttest: 0.5041636\tbest: 0.5041636 (71)\ttotal: 3m 44s\tremaining: 1m 27s\n",
      "72:\tlearn: 0.5013032\ttest: 0.5039950\tbest: 0.5039950 (72)\ttotal: 3m 47s\tremaining: 1m 24s\n",
      "73:\tlearn: 0.5011100\ttest: 0.5038782\tbest: 0.5038782 (73)\ttotal: 3m 50s\tremaining: 1m 20s\n",
      "74:\tlearn: 0.5007949\ttest: 0.5036446\tbest: 0.5036446 (74)\ttotal: 3m 53s\tremaining: 1m 17s\n",
      "75:\tlearn: 0.5005747\ttest: 0.5034695\tbest: 0.5034695 (75)\ttotal: 3m 57s\tremaining: 1m 14s\n",
      "76:\tlearn: 0.5003419\ttest: 0.5033027\tbest: 0.5033027 (76)\ttotal: 4m\tremaining: 1m 11s\n",
      "77:\tlearn: 0.5001073\ttest: 0.5031650\tbest: 0.5031650 (77)\ttotal: 4m 3s\tremaining: 1m 8s\n",
      "78:\tlearn: 0.4998929\ttest: 0.5030342\tbest: 0.5030342 (78)\ttotal: 4m 6s\tremaining: 1m 5s\n",
      "79:\tlearn: 0.4997173\ttest: 0.5029398\tbest: 0.5029398 (79)\ttotal: 4m 9s\tremaining: 1m 2s\n",
      "80:\tlearn: 0.4995224\ttest: 0.5027968\tbest: 0.5027968 (80)\ttotal: 4m 12s\tremaining: 59.3s\n",
      "81:\tlearn: 0.4992841\ttest: 0.5026291\tbest: 0.5026291 (81)\ttotal: 4m 15s\tremaining: 56.2s\n",
      "82:\tlearn: 0.4990975\ttest: 0.5024843\tbest: 0.5024843 (82)\ttotal: 4m 18s\tremaining: 53s\n",
      "83:\tlearn: 0.4989460\ttest: 0.5023766\tbest: 0.5023766 (83)\ttotal: 4m 22s\tremaining: 49.9s\n",
      "84:\tlearn: 0.4987588\ttest: 0.5022216\tbest: 0.5022216 (84)\ttotal: 4m 25s\tremaining: 46.8s\n",
      "85:\tlearn: 0.4986157\ttest: 0.5021071\tbest: 0.5021071 (85)\ttotal: 4m 28s\tremaining: 43.7s\n",
      "86:\tlearn: 0.4984748\ttest: 0.5020468\tbest: 0.5020468 (86)\ttotal: 4m 31s\tremaining: 40.5s\n",
      "87:\tlearn: 0.4983345\ttest: 0.5019429\tbest: 0.5019429 (87)\ttotal: 4m 34s\tremaining: 37.4s\n",
      "88:\tlearn: 0.4981025\ttest: 0.5018140\tbest: 0.5018140 (88)\ttotal: 4m 37s\tremaining: 34.3s\n",
      "89:\tlearn: 0.4979120\ttest: 0.5017267\tbest: 0.5017267 (89)\ttotal: 4m 40s\tremaining: 31.2s\n",
      "90:\tlearn: 0.4976873\ttest: 0.5015401\tbest: 0.5015401 (90)\ttotal: 4m 43s\tremaining: 28.1s\n",
      "91:\tlearn: 0.4975463\ttest: 0.5014727\tbest: 0.5014727 (91)\ttotal: 4m 47s\tremaining: 25s\n",
      "92:\tlearn: 0.4974333\ttest: 0.5013880\tbest: 0.5013880 (92)\ttotal: 4m 50s\tremaining: 21.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93:\tlearn: 0.4973080\ttest: 0.5013014\tbest: 0.5013014 (93)\ttotal: 4m 53s\tremaining: 18.7s\n",
      "94:\tlearn: 0.4970630\ttest: 0.5010601\tbest: 0.5010601 (94)\ttotal: 4m 56s\tremaining: 15.6s\n",
      "95:\tlearn: 0.4968842\ttest: 0.5009511\tbest: 0.5009511 (95)\ttotal: 4m 59s\tremaining: 12.5s\n",
      "96:\tlearn: 0.4967703\ttest: 0.5008993\tbest: 0.5008993 (96)\ttotal: 5m 2s\tremaining: 9.36s\n",
      "97:\tlearn: 0.4965697\ttest: 0.5007545\tbest: 0.5007545 (97)\ttotal: 5m 5s\tremaining: 6.24s\n",
      "98:\tlearn: 0.4963017\ttest: 0.5005246\tbest: 0.5005246 (98)\ttotal: 5m 9s\tremaining: 3.12s\n",
      "99:\tlearn: 0.4961731\ttest: 0.5004488\tbest: 0.5004488 (99)\ttotal: 5m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.50044878\n",
      "bestIteration = 99\n",
      "\n",
      "Shrink model to first 100 iterations.\n",
      "In [20] used 10.2266 MiB RAM in 380.94s, total RAM usage 20757.16 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t_train: \n",
    "    catboost_clf2.fit(X_train, y_train, cat_features=[], eval_set=(X_test, y_test), verbose=True, plot=False)\n",
    "with Timer() as t_test:  \n",
    "    y_pred = catboost_clf2.predict(X_test)\n",
    "extend_result('catboost2', t_train, t_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5986898\ttest: 0.5980496\tbest: 0.5980496 (0)\ttotal: 3.14s\tremaining: 10m 25s\n",
      "1:\tlearn: 0.5771127\ttest: 0.5761156\tbest: 0.5761156 (1)\ttotal: 6.26s\tremaining: 10m 19s\n",
      "2:\tlearn: 0.5657691\ttest: 0.5649751\tbest: 0.5649751 (2)\ttotal: 9.38s\tremaining: 10m 16s\n",
      "3:\tlearn: 0.5583664\ttest: 0.5574668\tbest: 0.5574668 (3)\ttotal: 12.6s\tremaining: 10m 15s\n",
      "4:\tlearn: 0.5526046\ttest: 0.5518329\tbest: 0.5518329 (4)\ttotal: 15.7s\tremaining: 10m 11s\n",
      "5:\tlearn: 0.5484880\ttest: 0.5478387\tbest: 0.5478387 (5)\ttotal: 18.7s\tremaining: 10m 5s\n",
      "6:\tlearn: 0.5456264\ttest: 0.5448630\tbest: 0.5448630 (6)\ttotal: 21.9s\tremaining: 10m 5s\n",
      "7:\tlearn: 0.5433129\ttest: 0.5424412\tbest: 0.5424412 (7)\ttotal: 25s\tremaining: 10m\n",
      "8:\tlearn: 0.5406706\ttest: 0.5399141\tbest: 0.5399141 (8)\ttotal: 28.2s\tremaining: 9m 58s\n",
      "9:\tlearn: 0.5381005\ttest: 0.5374030\tbest: 0.5374030 (9)\ttotal: 31.3s\tremaining: 9m 54s\n",
      "10:\tlearn: 0.5360710\ttest: 0.5354316\tbest: 0.5354316 (10)\ttotal: 34.4s\tremaining: 9m 50s\n",
      "11:\tlearn: 0.5345192\ttest: 0.5338550\tbest: 0.5338550 (11)\ttotal: 37.4s\tremaining: 9m 46s\n",
      "12:\tlearn: 0.5329451\ttest: 0.5323180\tbest: 0.5323180 (12)\ttotal: 40.5s\tremaining: 9m 42s\n",
      "13:\tlearn: 0.5313775\ttest: 0.5308564\tbest: 0.5308564 (13)\ttotal: 43.8s\tremaining: 9m 41s\n",
      "14:\tlearn: 0.5301827\ttest: 0.5296396\tbest: 0.5296396 (14)\ttotal: 46.8s\tremaining: 9m 37s\n",
      "15:\tlearn: 0.5287116\ttest: 0.5283585\tbest: 0.5283585 (15)\ttotal: 49.9s\tremaining: 9m 34s\n",
      "16:\tlearn: 0.5273593\ttest: 0.5270513\tbest: 0.5270513 (16)\ttotal: 53.1s\tremaining: 9m 31s\n",
      "17:\tlearn: 0.5265078\ttest: 0.5262953\tbest: 0.5262953 (17)\ttotal: 56.1s\tremaining: 9m 27s\n",
      "18:\tlearn: 0.5255853\ttest: 0.5254324\tbest: 0.5254324 (18)\ttotal: 59.2s\tremaining: 9m 23s\n",
      "19:\tlearn: 0.5246172\ttest: 0.5245817\tbest: 0.5245817 (19)\ttotal: 1m 2s\tremaining: 9m 21s\n",
      "20:\tlearn: 0.5238618\ttest: 0.5239136\tbest: 0.5239136 (20)\ttotal: 1m 5s\tremaining: 9m 17s\n",
      "21:\tlearn: 0.5229202\ttest: 0.5230922\tbest: 0.5230922 (21)\ttotal: 1m 8s\tremaining: 9m 15s\n",
      "22:\tlearn: 0.5222020\ttest: 0.5223830\tbest: 0.5223830 (22)\ttotal: 1m 11s\tremaining: 9m 11s\n",
      "23:\tlearn: 0.5215822\ttest: 0.5217252\tbest: 0.5217252 (23)\ttotal: 1m 14s\tremaining: 9m 7s\n",
      "24:\tlearn: 0.5209999\ttest: 0.5212324\tbest: 0.5212324 (24)\ttotal: 1m 17s\tremaining: 9m 3s\n",
      "25:\tlearn: 0.5201424\ttest: 0.5205185\tbest: 0.5205185 (25)\ttotal: 1m 20s\tremaining: 9m 1s\n",
      "26:\tlearn: 0.5194900\ttest: 0.5199036\tbest: 0.5199036 (26)\ttotal: 1m 24s\tremaining: 8m 58s\n",
      "27:\tlearn: 0.5190148\ttest: 0.5194655\tbest: 0.5194655 (27)\ttotal: 1m 27s\tremaining: 8m 55s\n",
      "28:\tlearn: 0.5183296\ttest: 0.5188396\tbest: 0.5188396 (28)\ttotal: 1m 30s\tremaining: 8m 52s\n",
      "29:\tlearn: 0.5177531\ttest: 0.5183393\tbest: 0.5183393 (29)\ttotal: 1m 33s\tremaining: 8m 48s\n",
      "30:\tlearn: 0.5170338\ttest: 0.5176551\tbest: 0.5176551 (30)\ttotal: 1m 36s\tremaining: 8m 46s\n",
      "31:\tlearn: 0.5161979\ttest: 0.5169447\tbest: 0.5169447 (31)\ttotal: 1m 39s\tremaining: 8m 43s\n",
      "32:\tlearn: 0.5155829\ttest: 0.5163253\tbest: 0.5163253 (32)\ttotal: 1m 42s\tremaining: 8m 40s\n",
      "33:\tlearn: 0.5147326\ttest: 0.5154772\tbest: 0.5154772 (33)\ttotal: 1m 46s\tremaining: 8m 37s\n",
      "34:\tlearn: 0.5142369\ttest: 0.5150549\tbest: 0.5150549 (34)\ttotal: 1m 49s\tremaining: 8m 34s\n",
      "35:\tlearn: 0.5137800\ttest: 0.5147026\tbest: 0.5147026 (35)\ttotal: 1m 52s\tremaining: 8m 31s\n",
      "36:\tlearn: 0.5134113\ttest: 0.5144388\tbest: 0.5144388 (36)\ttotal: 1m 55s\tremaining: 8m 28s\n",
      "37:\tlearn: 0.5128531\ttest: 0.5139101\tbest: 0.5139101 (37)\ttotal: 1m 58s\tremaining: 8m 25s\n",
      "38:\tlearn: 0.5124861\ttest: 0.5135326\tbest: 0.5135326 (38)\ttotal: 2m 1s\tremaining: 8m 22s\n",
      "39:\tlearn: 0.5120644\ttest: 0.5131479\tbest: 0.5131479 (39)\ttotal: 2m 4s\tremaining: 8m 18s\n",
      "40:\tlearn: 0.5115920\ttest: 0.5127586\tbest: 0.5127586 (40)\ttotal: 2m 7s\tremaining: 8m 15s\n",
      "41:\tlearn: 0.5111517\ttest: 0.5123844\tbest: 0.5123844 (41)\ttotal: 2m 10s\tremaining: 8m 12s\n",
      "42:\tlearn: 0.5105838\ttest: 0.5118988\tbest: 0.5118988 (42)\ttotal: 2m 14s\tremaining: 8m 9s\n",
      "43:\tlearn: 0.5100612\ttest: 0.5114501\tbest: 0.5114501 (43)\ttotal: 2m 17s\tremaining: 8m 6s\n",
      "44:\tlearn: 0.5097241\ttest: 0.5111440\tbest: 0.5111440 (44)\ttotal: 2m 20s\tremaining: 8m 3s\n",
      "45:\tlearn: 0.5092301\ttest: 0.5106345\tbest: 0.5106345 (45)\ttotal: 2m 23s\tremaining: 8m\n",
      "46:\tlearn: 0.5088202\ttest: 0.5103075\tbest: 0.5103075 (46)\ttotal: 2m 26s\tremaining: 7m 57s\n",
      "47:\tlearn: 0.5084577\ttest: 0.5100382\tbest: 0.5100382 (47)\ttotal: 2m 29s\tremaining: 7m 54s\n",
      "48:\tlearn: 0.5080725\ttest: 0.5096730\tbest: 0.5096730 (48)\ttotal: 2m 32s\tremaining: 7m 51s\n",
      "49:\tlearn: 0.5077344\ttest: 0.5094120\tbest: 0.5094120 (49)\ttotal: 2m 36s\tremaining: 7m 48s\n",
      "50:\tlearn: 0.5073945\ttest: 0.5091522\tbest: 0.5091522 (50)\ttotal: 2m 39s\tremaining: 7m 45s\n",
      "51:\tlearn: 0.5070308\ttest: 0.5088137\tbest: 0.5088137 (51)\ttotal: 2m 42s\tremaining: 7m 42s\n",
      "52:\tlearn: 0.5067084\ttest: 0.5085401\tbest: 0.5085401 (52)\ttotal: 2m 45s\tremaining: 7m 39s\n",
      "53:\tlearn: 0.5064784\ttest: 0.5082953\tbest: 0.5082953 (53)\ttotal: 2m 48s\tremaining: 7m 35s\n",
      "54:\tlearn: 0.5061279\ttest: 0.5080196\tbest: 0.5080196 (54)\ttotal: 2m 51s\tremaining: 7m 32s\n",
      "55:\tlearn: 0.5058640\ttest: 0.5077863\tbest: 0.5077863 (55)\ttotal: 2m 54s\tremaining: 7m 29s\n",
      "56:\tlearn: 0.5056153\ttest: 0.5075667\tbest: 0.5075667 (56)\ttotal: 2m 57s\tremaining: 7m 26s\n",
      "57:\tlearn: 0.5052756\ttest: 0.5072711\tbest: 0.5072711 (57)\ttotal: 3m\tremaining: 7m 23s\n",
      "58:\tlearn: 0.5049238\ttest: 0.5069797\tbest: 0.5069797 (58)\ttotal: 3m 4s\tremaining: 7m 20s\n",
      "59:\tlearn: 0.5046240\ttest: 0.5067593\tbest: 0.5067593 (59)\ttotal: 3m 7s\tremaining: 7m 17s\n",
      "60:\tlearn: 0.5043910\ttest: 0.5065959\tbest: 0.5065959 (60)\ttotal: 3m 10s\tremaining: 7m 13s\n",
      "61:\tlearn: 0.5039834\ttest: 0.5061906\tbest: 0.5061906 (61)\ttotal: 3m 13s\tremaining: 7m 10s\n",
      "62:\tlearn: 0.5037335\ttest: 0.5059451\tbest: 0.5059451 (62)\ttotal: 3m 16s\tremaining: 7m 7s\n",
      "63:\tlearn: 0.5034988\ttest: 0.5057775\tbest: 0.5057775 (63)\ttotal: 3m 19s\tremaining: 7m 4s\n",
      "64:\tlearn: 0.5032343\ttest: 0.5055593\tbest: 0.5055593 (64)\ttotal: 3m 22s\tremaining: 7m 1s\n",
      "65:\tlearn: 0.5028040\ttest: 0.5051093\tbest: 0.5051093 (65)\ttotal: 3m 26s\tremaining: 6m 58s\n",
      "66:\tlearn: 0.5025782\ttest: 0.5049990\tbest: 0.5049990 (66)\ttotal: 3m 29s\tremaining: 6m 55s\n",
      "67:\tlearn: 0.5023412\ttest: 0.5047751\tbest: 0.5047751 (67)\ttotal: 3m 32s\tremaining: 6m 52s\n",
      "68:\tlearn: 0.5021883\ttest: 0.5046491\tbest: 0.5046491 (68)\ttotal: 3m 35s\tremaining: 6m 48s\n",
      "69:\tlearn: 0.5018623\ttest: 0.5044539\tbest: 0.5044539 (69)\ttotal: 3m 38s\tremaining: 6m 45s\n",
      "70:\tlearn: 0.5016734\ttest: 0.5042977\tbest: 0.5042977 (70)\ttotal: 3m 41s\tremaining: 6m 42s\n",
      "71:\tlearn: 0.5014499\ttest: 0.5040902\tbest: 0.5040902 (71)\ttotal: 3m 44s\tremaining: 6m 39s\n",
      "72:\tlearn: 0.5012969\ttest: 0.5039944\tbest: 0.5039944 (72)\ttotal: 3m 47s\tremaining: 6m 36s\n",
      "73:\tlearn: 0.5011230\ttest: 0.5038681\tbest: 0.5038681 (73)\ttotal: 3m 50s\tremaining: 6m 33s\n",
      "74:\tlearn: 0.5009902\ttest: 0.5037684\tbest: 0.5037684 (74)\ttotal: 3m 53s\tremaining: 6m 29s\n",
      "75:\tlearn: 0.5007891\ttest: 0.5036053\tbest: 0.5036053 (75)\ttotal: 3m 56s\tremaining: 6m 26s\n",
      "76:\tlearn: 0.5006048\ttest: 0.5034602\tbest: 0.5034602 (76)\ttotal: 4m\tremaining: 6m 23s\n",
      "77:\tlearn: 0.5003879\ttest: 0.5033267\tbest: 0.5033267 (77)\ttotal: 4m 3s\tremaining: 6m 20s\n",
      "78:\tlearn: 0.5002071\ttest: 0.5032212\tbest: 0.5032212 (78)\ttotal: 4m 6s\tremaining: 6m 17s\n",
      "79:\tlearn: 0.5000239\ttest: 0.5030710\tbest: 0.5030710 (79)\ttotal: 4m 9s\tremaining: 6m 14s\n",
      "80:\tlearn: 0.4998227\ttest: 0.5028690\tbest: 0.5028690 (80)\ttotal: 4m 12s\tremaining: 6m 11s\n",
      "81:\tlearn: 0.4996669\ttest: 0.5027323\tbest: 0.5027323 (81)\ttotal: 4m 15s\tremaining: 6m 7s\n",
      "82:\tlearn: 0.4994484\ttest: 0.5025949\tbest: 0.5025949 (82)\ttotal: 4m 18s\tremaining: 6m 4s\n",
      "83:\tlearn: 0.4992903\ttest: 0.5024915\tbest: 0.5024915 (83)\ttotal: 4m 22s\tremaining: 6m 1s\n",
      "84:\tlearn: 0.4991064\ttest: 0.5023563\tbest: 0.5023563 (84)\ttotal: 4m 25s\tremaining: 5m 58s\n",
      "85:\tlearn: 0.4989935\ttest: 0.5022835\tbest: 0.5022835 (85)\ttotal: 4m 28s\tremaining: 5m 55s\n",
      "86:\tlearn: 0.4988309\ttest: 0.5021998\tbest: 0.5021998 (86)\ttotal: 4m 31s\tremaining: 5m 52s\n",
      "87:\tlearn: 0.4986577\ttest: 0.5020684\tbest: 0.5020684 (87)\ttotal: 4m 34s\tremaining: 5m 49s\n",
      "88:\tlearn: 0.4983593\ttest: 0.5018226\tbest: 0.5018226 (88)\ttotal: 4m 37s\tremaining: 5m 45s\n",
      "89:\tlearn: 0.4982080\ttest: 0.5016881\tbest: 0.5016881 (89)\ttotal: 4m 40s\tremaining: 5m 42s\n",
      "90:\tlearn: 0.4980100\ttest: 0.5015217\tbest: 0.5015217 (90)\ttotal: 4m 43s\tremaining: 5m 39s\n",
      "91:\tlearn: 0.4978164\ttest: 0.5013787\tbest: 0.5013787 (91)\ttotal: 4m 46s\tremaining: 5m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92:\tlearn: 0.4975785\ttest: 0.5011863\tbest: 0.5011863 (92)\ttotal: 4m 49s\tremaining: 5m 33s\n",
      "93:\tlearn: 0.4973843\ttest: 0.5010351\tbest: 0.5010351 (93)\ttotal: 4m 53s\tremaining: 5m 30s\n",
      "94:\tlearn: 0.4971849\ttest: 0.5008694\tbest: 0.5008694 (94)\ttotal: 4m 56s\tremaining: 5m 27s\n",
      "95:\tlearn: 0.4969902\ttest: 0.5007166\tbest: 0.5007166 (95)\ttotal: 4m 59s\tremaining: 5m 24s\n",
      "96:\tlearn: 0.4968632\ttest: 0.5006230\tbest: 0.5006230 (96)\ttotal: 5m 2s\tremaining: 5m 21s\n",
      "97:\tlearn: 0.4967079\ttest: 0.5005497\tbest: 0.5005497 (97)\ttotal: 5m 5s\tremaining: 5m 18s\n",
      "98:\tlearn: 0.4966036\ttest: 0.5005104\tbest: 0.5005104 (98)\ttotal: 5m 8s\tremaining: 5m 14s\n",
      "99:\tlearn: 0.4963641\ttest: 0.5003361\tbest: 0.5003361 (99)\ttotal: 5m 11s\tremaining: 5m 11s\n",
      "100:\tlearn: 0.4962340\ttest: 0.5002660\tbest: 0.5002660 (100)\ttotal: 5m 14s\tremaining: 5m 8s\n",
      "101:\tlearn: 0.4960315\ttest: 0.5001330\tbest: 0.5001330 (101)\ttotal: 5m 18s\tremaining: 5m 5s\n",
      "102:\tlearn: 0.4959010\ttest: 0.5000654\tbest: 0.5000654 (102)\ttotal: 5m 21s\tremaining: 5m 2s\n",
      "103:\tlearn: 0.4957532\ttest: 0.4999328\tbest: 0.4999328 (103)\ttotal: 5m 24s\tremaining: 4m 59s\n",
      "104:\tlearn: 0.4956065\ttest: 0.4998652\tbest: 0.4998652 (104)\ttotal: 5m 27s\tremaining: 4m 56s\n",
      "105:\tlearn: 0.4955041\ttest: 0.4998128\tbest: 0.4998128 (105)\ttotal: 5m 30s\tremaining: 4m 52s\n",
      "106:\tlearn: 0.4953332\ttest: 0.4997015\tbest: 0.4997015 (106)\ttotal: 5m 33s\tremaining: 4m 49s\n",
      "107:\tlearn: 0.4951005\ttest: 0.4995089\tbest: 0.4995089 (107)\ttotal: 5m 36s\tremaining: 4m 46s\n",
      "108:\tlearn: 0.4949196\ttest: 0.4993857\tbest: 0.4993857 (108)\ttotal: 5m 39s\tremaining: 4m 43s\n",
      "109:\tlearn: 0.4947651\ttest: 0.4992778\tbest: 0.4992778 (109)\ttotal: 5m 43s\tremaining: 4m 40s\n",
      "110:\tlearn: 0.4945978\ttest: 0.4991494\tbest: 0.4991494 (110)\ttotal: 5m 46s\tremaining: 4m 37s\n",
      "111:\tlearn: 0.4944945\ttest: 0.4990655\tbest: 0.4990655 (111)\ttotal: 5m 49s\tremaining: 4m 34s\n",
      "112:\tlearn: 0.4943442\ttest: 0.4989720\tbest: 0.4989720 (112)\ttotal: 5m 52s\tremaining: 4m 31s\n",
      "113:\tlearn: 0.4942176\ttest: 0.4988856\tbest: 0.4988856 (113)\ttotal: 5m 55s\tremaining: 4m 28s\n",
      "114:\tlearn: 0.4939908\ttest: 0.4986767\tbest: 0.4986767 (114)\ttotal: 5m 58s\tremaining: 4m 25s\n",
      "115:\tlearn: 0.4937858\ttest: 0.4985234\tbest: 0.4985234 (115)\ttotal: 6m 1s\tremaining: 4m 22s\n",
      "116:\tlearn: 0.4936609\ttest: 0.4984602\tbest: 0.4984602 (116)\ttotal: 6m 5s\tremaining: 4m 19s\n",
      "117:\tlearn: 0.4934567\ttest: 0.4983407\tbest: 0.4983407 (117)\ttotal: 6m 8s\tremaining: 4m 15s\n",
      "118:\tlearn: 0.4932880\ttest: 0.4981805\tbest: 0.4981805 (118)\ttotal: 6m 11s\tremaining: 4m 12s\n",
      "119:\tlearn: 0.4931589\ttest: 0.4981260\tbest: 0.4981260 (119)\ttotal: 6m 14s\tremaining: 4m 9s\n",
      "120:\tlearn: 0.4930506\ttest: 0.4980775\tbest: 0.4980775 (120)\ttotal: 6m 17s\tremaining: 4m 6s\n",
      "121:\tlearn: 0.4929267\ttest: 0.4979903\tbest: 0.4979903 (121)\ttotal: 6m 20s\tremaining: 4m 3s\n",
      "122:\tlearn: 0.4927188\ttest: 0.4977768\tbest: 0.4977768 (122)\ttotal: 6m 23s\tremaining: 4m\n",
      "123:\tlearn: 0.4926158\ttest: 0.4977201\tbest: 0.4977201 (123)\ttotal: 6m 26s\tremaining: 3m 57s\n",
      "124:\tlearn: 0.4925190\ttest: 0.4976945\tbest: 0.4976945 (124)\ttotal: 6m 30s\tremaining: 3m 54s\n",
      "125:\tlearn: 0.4923605\ttest: 0.4976145\tbest: 0.4976145 (125)\ttotal: 6m 33s\tremaining: 3m 50s\n",
      "126:\tlearn: 0.4922313\ttest: 0.4975603\tbest: 0.4975603 (126)\ttotal: 6m 36s\tremaining: 3m 47s\n",
      "127:\tlearn: 0.4921192\ttest: 0.4974934\tbest: 0.4974934 (127)\ttotal: 6m 39s\tremaining: 3m 44s\n",
      "128:\tlearn: 0.4919992\ttest: 0.4974224\tbest: 0.4974224 (128)\ttotal: 6m 42s\tremaining: 3m 41s\n",
      "129:\tlearn: 0.4918705\ttest: 0.4973782\tbest: 0.4973782 (129)\ttotal: 6m 45s\tremaining: 3m 38s\n",
      "130:\tlearn: 0.4917395\ttest: 0.4972792\tbest: 0.4972792 (130)\ttotal: 6m 48s\tremaining: 3m 35s\n",
      "131:\tlearn: 0.4916199\ttest: 0.4972197\tbest: 0.4972197 (131)\ttotal: 6m 52s\tremaining: 3m 32s\n",
      "132:\tlearn: 0.4915102\ttest: 0.4971757\tbest: 0.4971757 (132)\ttotal: 6m 55s\tremaining: 3m 29s\n",
      "133:\tlearn: 0.4914109\ttest: 0.4971421\tbest: 0.4971421 (133)\ttotal: 6m 58s\tremaining: 3m 25s\n",
      "134:\tlearn: 0.4912596\ttest: 0.4970074\tbest: 0.4970074 (134)\ttotal: 7m 1s\tremaining: 3m 22s\n",
      "135:\tlearn: 0.4911475\ttest: 0.4969477\tbest: 0.4969477 (135)\ttotal: 7m 4s\tremaining: 3m 19s\n",
      "136:\tlearn: 0.4910372\ttest: 0.4968841\tbest: 0.4968841 (136)\ttotal: 7m 7s\tremaining: 3m 16s\n",
      "137:\tlearn: 0.4909721\ttest: 0.4968596\tbest: 0.4968596 (137)\ttotal: 7m 10s\tremaining: 3m 13s\n",
      "138:\tlearn: 0.4908638\ttest: 0.4967579\tbest: 0.4967579 (138)\ttotal: 7m 13s\tremaining: 3m 10s\n",
      "139:\tlearn: 0.4907443\ttest: 0.4966713\tbest: 0.4966713 (139)\ttotal: 7m 16s\tremaining: 3m 7s\n",
      "140:\tlearn: 0.4905798\ttest: 0.4965654\tbest: 0.4965654 (140)\ttotal: 7m 19s\tremaining: 3m 4s\n",
      "141:\tlearn: 0.4905137\ttest: 0.4965321\tbest: 0.4965321 (141)\ttotal: 7m 23s\tremaining: 3m\n",
      "142:\tlearn: 0.4903991\ttest: 0.4964830\tbest: 0.4964830 (142)\ttotal: 7m 26s\tremaining: 2m 57s\n",
      "143:\tlearn: 0.4903098\ttest: 0.4964451\tbest: 0.4964451 (143)\ttotal: 7m 29s\tremaining: 2m 54s\n",
      "144:\tlearn: 0.4901897\ttest: 0.4963922\tbest: 0.4963922 (144)\ttotal: 7m 32s\tremaining: 2m 51s\n",
      "145:\tlearn: 0.4900413\ttest: 0.4962628\tbest: 0.4962628 (145)\ttotal: 7m 35s\tremaining: 2m 48s\n",
      "146:\tlearn: 0.4899770\ttest: 0.4962443\tbest: 0.4962443 (146)\ttotal: 7m 38s\tremaining: 2m 45s\n",
      "147:\tlearn: 0.4898794\ttest: 0.4961987\tbest: 0.4961987 (147)\ttotal: 7m 41s\tremaining: 2m 42s\n",
      "148:\tlearn: 0.4897697\ttest: 0.4961512\tbest: 0.4961512 (148)\ttotal: 7m 44s\tremaining: 2m 39s\n",
      "149:\tlearn: 0.4896438\ttest: 0.4960797\tbest: 0.4960797 (149)\ttotal: 7m 48s\tremaining: 2m 36s\n",
      "150:\tlearn: 0.4895167\ttest: 0.4960082\tbest: 0.4960082 (150)\ttotal: 7m 51s\tremaining: 2m 32s\n",
      "151:\tlearn: 0.4893973\ttest: 0.4959674\tbest: 0.4959674 (151)\ttotal: 7m 54s\tremaining: 2m 29s\n",
      "152:\tlearn: 0.4893217\ttest: 0.4959339\tbest: 0.4959339 (152)\ttotal: 7m 57s\tremaining: 2m 26s\n",
      "153:\tlearn: 0.4892381\ttest: 0.4958951\tbest: 0.4958951 (153)\ttotal: 8m\tremaining: 2m 23s\n",
      "154:\tlearn: 0.4891053\ttest: 0.4957977\tbest: 0.4957977 (154)\ttotal: 8m 3s\tremaining: 2m 20s\n",
      "155:\tlearn: 0.4890082\ttest: 0.4957100\tbest: 0.4957100 (155)\ttotal: 8m 6s\tremaining: 2m 17s\n",
      "156:\tlearn: 0.4889027\ttest: 0.4956240\tbest: 0.4956240 (156)\ttotal: 8m 9s\tremaining: 2m 14s\n",
      "157:\tlearn: 0.4887732\ttest: 0.4955760\tbest: 0.4955760 (157)\ttotal: 8m 12s\tremaining: 2m 10s\n",
      "158:\tlearn: 0.4886824\ttest: 0.4955610\tbest: 0.4955610 (158)\ttotal: 8m 15s\tremaining: 2m 7s\n",
      "159:\tlearn: 0.4885627\ttest: 0.4954785\tbest: 0.4954785 (159)\ttotal: 8m 19s\tremaining: 2m 4s\n",
      "160:\tlearn: 0.4884786\ttest: 0.4954607\tbest: 0.4954607 (160)\ttotal: 8m 22s\tremaining: 2m 1s\n",
      "161:\tlearn: 0.4883799\ttest: 0.4953936\tbest: 0.4953936 (161)\ttotal: 8m 25s\tremaining: 1m 58s\n",
      "162:\tlearn: 0.4882904\ttest: 0.4954051\tbest: 0.4953936 (161)\ttotal: 8m 28s\tremaining: 1m 55s\n",
      "163:\tlearn: 0.4881785\ttest: 0.4953582\tbest: 0.4953582 (163)\ttotal: 8m 31s\tremaining: 1m 52s\n",
      "164:\tlearn: 0.4880590\ttest: 0.4953027\tbest: 0.4953027 (164)\ttotal: 8m 34s\tremaining: 1m 49s\n",
      "165:\tlearn: 0.4874861\ttest: 0.4948618\tbest: 0.4948618 (165)\ttotal: 8m 38s\tremaining: 1m 46s\n",
      "166:\tlearn: 0.4873705\ttest: 0.4948347\tbest: 0.4948347 (166)\ttotal: 8m 41s\tremaining: 1m 42s\n",
      "167:\tlearn: 0.4872470\ttest: 0.4947333\tbest: 0.4947333 (167)\ttotal: 8m 44s\tremaining: 1m 39s\n",
      "168:\tlearn: 0.4871323\ttest: 0.4946958\tbest: 0.4946958 (168)\ttotal: 8m 47s\tremaining: 1m 36s\n",
      "169:\tlearn: 0.4870198\ttest: 0.4946217\tbest: 0.4946217 (169)\ttotal: 8m 50s\tremaining: 1m 33s\n",
      "170:\tlearn: 0.4868746\ttest: 0.4945904\tbest: 0.4945904 (170)\ttotal: 8m 53s\tremaining: 1m 30s\n",
      "171:\tlearn: 0.4867775\ttest: 0.4945353\tbest: 0.4945353 (171)\ttotal: 8m 56s\tremaining: 1m 27s\n",
      "172:\tlearn: 0.4867164\ttest: 0.4945212\tbest: 0.4945212 (172)\ttotal: 8m 59s\tremaining: 1m 24s\n",
      "173:\tlearn: 0.4866310\ttest: 0.4944812\tbest: 0.4944812 (173)\ttotal: 9m 3s\tremaining: 1m 21s\n",
      "174:\tlearn: 0.4865049\ttest: 0.4944353\tbest: 0.4944353 (174)\ttotal: 9m 6s\tremaining: 1m 18s\n",
      "175:\tlearn: 0.4863889\ttest: 0.4943889\tbest: 0.4943889 (175)\ttotal: 9m 9s\tremaining: 1m 14s\n",
      "176:\tlearn: 0.4862750\ttest: 0.4943294\tbest: 0.4943294 (176)\ttotal: 9m 12s\tremaining: 1m 11s\n",
      "177:\tlearn: 0.4861851\ttest: 0.4942467\tbest: 0.4942467 (177)\ttotal: 9m 15s\tremaining: 1m 8s\n",
      "178:\tlearn: 0.4860840\ttest: 0.4942170\tbest: 0.4942170 (178)\ttotal: 9m 18s\tremaining: 1m 5s\n",
      "179:\tlearn: 0.4860053\ttest: 0.4941717\tbest: 0.4941717 (179)\ttotal: 9m 21s\tremaining: 1m 2s\n",
      "180:\tlearn: 0.4859480\ttest: 0.4941240\tbest: 0.4941240 (180)\ttotal: 9m 24s\tremaining: 59.3s\n",
      "181:\tlearn: 0.4858308\ttest: 0.4940860\tbest: 0.4940860 (181)\ttotal: 9m 28s\tremaining: 56.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182:\tlearn: 0.4857267\ttest: 0.4940868\tbest: 0.4940860 (181)\ttotal: 9m 31s\tremaining: 53.1s\n",
      "183:\tlearn: 0.4853943\ttest: 0.4938091\tbest: 0.4938091 (183)\ttotal: 9m 34s\tremaining: 49.9s\n",
      "184:\tlearn: 0.4852998\ttest: 0.4937834\tbest: 0.4937834 (184)\ttotal: 9m 37s\tremaining: 46.8s\n",
      "185:\tlearn: 0.4852528\ttest: 0.4937783\tbest: 0.4937783 (185)\ttotal: 9m 40s\tremaining: 43.7s\n",
      "186:\tlearn: 0.4850810\ttest: 0.4936348\tbest: 0.4936348 (186)\ttotal: 9m 43s\tremaining: 40.6s\n",
      "187:\tlearn: 0.4849878\ttest: 0.4936230\tbest: 0.4936230 (187)\ttotal: 9m 46s\tremaining: 37.5s\n",
      "188:\tlearn: 0.4849135\ttest: 0.4936021\tbest: 0.4936021 (188)\ttotal: 9m 49s\tremaining: 34.3s\n",
      "189:\tlearn: 0.4847696\ttest: 0.4935386\tbest: 0.4935386 (189)\ttotal: 9m 53s\tremaining: 31.2s\n",
      "190:\tlearn: 0.4846980\ttest: 0.4935306\tbest: 0.4935306 (190)\ttotal: 9m 56s\tremaining: 28.1s\n",
      "191:\tlearn: 0.4846100\ttest: 0.4935099\tbest: 0.4935099 (191)\ttotal: 9m 59s\tremaining: 25s\n",
      "192:\tlearn: 0.4843260\ttest: 0.4932621\tbest: 0.4932621 (192)\ttotal: 10m 2s\tremaining: 21.9s\n",
      "193:\tlearn: 0.4842108\ttest: 0.4932139\tbest: 0.4932139 (193)\ttotal: 10m 5s\tremaining: 18.7s\n",
      "194:\tlearn: 0.4841024\ttest: 0.4931459\tbest: 0.4931459 (194)\ttotal: 10m 9s\tremaining: 15.6s\n",
      "195:\tlearn: 0.4840129\ttest: 0.4930854\tbest: 0.4930854 (195)\ttotal: 10m 12s\tremaining: 12.5s\n",
      "196:\tlearn: 0.4839022\ttest: 0.4930127\tbest: 0.4930127 (196)\ttotal: 10m 15s\tremaining: 9.37s\n",
      "197:\tlearn: 0.4837916\ttest: 0.4929368\tbest: 0.4929368 (197)\ttotal: 10m 18s\tremaining: 6.25s\n",
      "198:\tlearn: 0.4837090\ttest: 0.4929041\tbest: 0.4929041 (198)\ttotal: 10m 21s\tremaining: 3.12s\n",
      "199:\tlearn: 0.4836171\ttest: 0.4928857\tbest: 0.4928857 (199)\ttotal: 10m 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4928856509\n",
      "bestIteration = 199\n",
      "\n",
      "Shrink model to first 200 iterations.\n",
      "In [21] used -3555.5156 MiB RAM in 698.43s, total RAM usage 17201.64 MiB\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t_train: \n",
    "    catboost_clf3.fit(X_train, y_train, cat_features=[], eval_set=(X_test, y_test), verbose=True, plot=False)\n",
    "with Timer() as t_test:  \n",
    "    y_pred = catboost_clf3.predict(X_test)\n",
    "extend_result('catboost3', t_train, t_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"catboost1\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.7419166857815135,\n",
      "            \"Accuracy\": 0.743498,\n",
      "            \"F1\": 0.7604625231831247,\n",
      "            \"Precision\": 0.752742640995966,\n",
      "            \"Recall\": 0.7683423913043478\n",
      "        },\n",
      "        \"test_time\": 1.0937234009616077,\n",
      "        \"train_mem\": 12.3203125,\n",
      "        \"train_time\": 220.42882245406508\n",
      "    },\n",
      "    \"catboost2\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.748363189747947,\n",
      "            \"Accuracy\": 0.749914,\n",
      "            \"F1\": 0.7664271344487428,\n",
      "            \"Precision\": 0.7587327886859303,\n",
      "            \"Recall\": 0.7742791364734299\n",
      "        },\n",
      "        \"test_time\": 1.1106334659270942,\n",
      "        \"train_mem\": 4.22265625,\n",
      "        \"train_time\": 379.0510009857826\n",
      "    },\n",
      "    \"catboost3\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.7535612424280542,\n",
      "            \"Accuracy\": 0.755168,\n",
      "            \"F1\": 0.7716000089556918,\n",
      "            \"Precision\": 0.7629846648856877,\n",
      "            \"Recall\": 0.7804121376811595\n",
      "        },\n",
      "        \"test_time\": 1.1669284170493484,\n",
      "        \"train_mem\": 84.953125,\n",
      "        \"train_time\": 696.4923489103094\n",
      "    },\n",
      "    \"lgbm\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.6939240517288865,\n",
      "            \"Accuracy\": 0.707054,\n",
      "            \"F1\": 0.7676768638049966,\n",
      "            \"Precision\": 0.6620840412463647,\n",
      "            \"Recall\": 0.9133416364734299\n",
      "        },\n",
      "        \"test_time\": 1.2589309690520167,\n",
      "        \"train_mem\": 0.0,\n",
      "        \"train_time\": 121.58115790318698\n",
      "    },\n",
      "    \"xgb_hist\": {\n",
      "        \"performance\": {\n",
      "            \"AUC\": 0.6941216899970567,\n",
      "            \"Accuracy\": 0.70721,\n",
      "            \"F1\": 0.767674555527519,\n",
      "            \"Precision\": 0.6623426413523601,\n",
      "            \"Recall\": 0.9128434480676328\n",
      "        },\n",
      "        \"test_time\": 5.741467632818967,\n",
      "        \"train_mem\": 0.0,\n",
      "        \"train_time\": 193.75250169215724\n",
      "    }\n",
      "}\n",
      "In [22] used 0.0000 MiB RAM in 0.10s, total RAM usage 17201.64 MiB\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(json.dumps(results_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
